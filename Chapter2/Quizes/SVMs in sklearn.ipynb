{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "When we define the model, we can specify the hyperparameters. As we've seen in this section, the most common ones are\n",
    "\n",
    "* `C`: The C parameter.\n",
    "* `kernel`: The kernel. The most common ones are 'linear', 'poly', and 'rbf'.\n",
    "* `degree`: If the kernel is polynomial, this is the maximum degree of the monomials in the kernel.\n",
    "* `gamma` : If the kernel is rbf, this is the gamma parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file can be found under the \"data.csv\" tab in the quiz below. It includes three columns, the first 2 comprising of the coordinates of the points, and the third one of the label.\n",
    "\n",
    "The data will be loaded for you, and split into features X and labels y.\n",
    "\n",
    "You'll need to complete each of the following steps:\n",
    "1. Build a support vector machine model\n",
    "\n",
    "Create a support vector machine classification model using scikit-learn's SVC and assign it to the variablemodel.\n",
    "2. Fit the model to the data\n",
    "\n",
    "If necessary, specify some of the hyperparameters. The goal is to obtain an accuracy of 100% in the dataset. Hint: Not every kernel will work well.\n",
    "3. Predict using the model\n",
    "\n",
    "Predict the labels for the training set, and assign this list to the variable y_pred.\n",
    "4. Calculate the accuracy of the model\n",
    "\n",
    "For this, use the function sklearn function accuracy_score.\n",
    "When you hit Test Run, you'll be able to see the boundary region of your model, which will help you tune the correct parameters, in case you need them.\n",
    "\n",
    "Note: This quiz requires you to find an accuracy of 100% on the training set. Of course, this screams overfitting! If you pick very large values for your parameters, you will fit the training set very well, but it may not be the best model. Try to find the smallest possible parameters that do the job, which has less chance of overfitting, although this part won't be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = np.asarray(pd.read_csv('testData/svcData.csv', header=None))\n",
    "X = data[:, 0:2]\n",
    "y = data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the right parameters for this model to achieve 100% accuracy on the dataset.\n",
    "param_grid = {'kernel':['rbf'], 'gamma': np.arange(18, 29)}\n",
    "# Train the model\n",
    "model = GridSearchCV(SVC(), param_grid)\n",
    "# tree = DecisionTreeClassifier()\n",
    "# model = GridSearchCV(tree, param_grid)\n",
    "# model.fit(X_train, y_train)\n",
    "# model = SVC(gamma=27, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'gamma': array([18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]),\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "{'gamma': 27, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "acc = accuracy_score(y, y_pred)\n",
    "print(acc)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
